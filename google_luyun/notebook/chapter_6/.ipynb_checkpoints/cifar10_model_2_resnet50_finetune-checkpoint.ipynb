{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.2\n",
      "numpy 1.19.0\n",
      "pandas 1.0.5\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck',\n",
    "]\n",
    "\n",
    "# 注意查看 文件路径\n",
    "\"\"\"kaggle\n",
    "train_labels_file = '../input/cifar10-object-recognition-in-images-zip-file/trainLabels.csv'\n",
    "test_csv_file = '../input/cifar10-object-recognition-in-images-zip-file/sampleSubmission.csv'\n",
    "train_folder = '../input/cifar10-object-recognition-in-images-zip-file/train_test/train/train/'\n",
    "test_folder = '../input/cifar10-object-recognition-in-images-zip-file/train_test/test/test/'\n",
    "\n",
    "\"\"\"\n",
    "train_labels_file = './cifar10/trainLabels.csv'\n",
    "test_csv_file = './cifar10/sampleSubmission.csv'\n",
    "train_folder = './cifar10/train/'\n",
    "test_folder = './cifar10/test/'\n",
    "\n",
    "print(os.path.exists(train_folder))\n",
    "print(os.path.exists(test_folder))\n",
    "print(os.path.exists(train_labels_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据，组装数据\n",
    "# Parses csv files into (filename(path),label) format\n",
    "def parse_csv_file(filepath,folder):\n",
    "    results = []\n",
    "    with open(filepath,'r') as f:\n",
    "        lines = f.readlines()[1:]  #不需要header \n",
    "    for line in lines:\n",
    "        image_id,label_str = line.strip('\\n').split(',')\n",
    "        image_full_path = os.path.join(folder,image_id+'.png')\n",
    "        results.append((image_full_path,label_str))\n",
    "    return results\n",
    "\n",
    "train_labels_info = parse_csv_file(train_labels_file,train_folder)\n",
    "test_csv_info = parse_csv_file(test_csv_file,test_folder)\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(train_labels_info[0:5])\n",
    "pprint.pprint(test_csv_info[0:5])\n",
    "print(len(train_labels_info),len(test_csv_info))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.DataFrame(train_labels_info)\n",
    "train_df = pd.DataFrame(train_labels_info[0:45000])\n",
    "valid_df = pd.DataFrame(train_labels_info[45000:])\n",
    "test_df = pd.DataFrame(test_csv_info)\n",
    "\n",
    "print(train_df.head())\n",
    "print(valid_df.head())\n",
    "print(test_df.head())\n",
    "# 添加列 别名\n",
    "train_df.columns = ['filepath','class']\n",
    "valid_df.columns = ['filepath','class']\n",
    "test_df.columns = ['filepath','class']\n",
    "\n",
    "print(train_df.head())\n",
    "print(valid_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络无法预处理大小不一致的图片，所以要对读取的图片进行大小变化\n",
    "# resnet50 图片是  224*224\n",
    "height = 224\n",
    "width = 224\n",
    "channels = 3 \n",
    "batch_size = 24\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# keras.preprocessing.image.ImageDataGenerator\n",
    "# keras.applications.resnet50.preprocess_input\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = keras.applications.resnet50.preprocess_input,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "# flow_from_dataframe\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory = './',\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'class',\n",
    "    classes = class_names,\n",
    "    target_size = (height,width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 7,\n",
    "    shuffle = True,\n",
    "    class_mode = 'sparse'\n",
    ")\n",
    "\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = keras.applications.resnet50.preprocess_input\n",
    ")\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    directory = './',\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'class',\n",
    "    calsses = class_names,\n",
    "    target_size = (height,width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 7,\n",
    "    shuffle = False,\n",
    "    class_mode = 'sparse'\n",
    ")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "print(train_num,valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    x,y = train_generator.next()\n",
    "    print(x.shape,y.shape)\n",
    "    print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.applications.ResNet50\n",
    "resnet50_fine_tune = keras.models.Sequential()\n",
    "resnet50_fine_tune.add(keras.applications.ResNet50(include_top =False,pooling='avg',weights='imagenet' ))\n",
    "resnet50_fine_tune.add(keras.layers.Dense(num_classes,activation='softmax'))\n",
    "resnet50_fine_tune.layers[0].trainable=False\n",
    "resnet50_fine_tune.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy']) # finetune -> sgd\n",
    "resnet50_fine_tune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator\n",
    "history = resnet50_fine_tune.fit_generator(train_generator,steps_per_epoch=train_num//batch_size,epochs=epochs,validation_data=valid_generator,validation_steps=valid_num//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.getkeys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_leraning_curves(history, label, epochs, min_value, max_value):\n",
    "    data = {}\n",
    "    data[label] = history.history[label]\n",
    "    data['val_'+label] = history.history['val_'+label]\n",
    "    pd.DataFrame(data).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.axis([0, epochs, min_value, max_value])\n",
    "    plt.show()\n",
    "    \n",
    "plot_leraning_curves(history, 'accuracy', epochs, 0, 1)\n",
    "plot_leraning_curves(history, 'loss', epochs, 1.0, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    directory = './',\n",
    "    x_col = 'filepath',\n",
    "    y_col = 'class',\n",
    "    classes = class_names,\n",
    "    target_size = (height,width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 7,\n",
    "    shuffle = False,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "test_num = test_generator.samples\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict_generator\n",
    "test_predict = resnet50_fine_tune.predict_generator(test_generator,workers=10,multiprocessing=False)\n",
    "print(test_predict.shape)\n",
    "print(test_predict[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_class_indiecs = np.argmax(test_predict,axis=1) # axis=1行\n",
    "print(test_predict_class_indiecs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_class = [class_names[index] for index in test_predict_class_indiecs] #根据index获取class name\n",
    "print(test_predict_class[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果写入文件\n",
    "def generate_submissions(filename,predict_class):\n",
    "    with open(filename,'w') as f:\n",
    "        f.write('id,label\\n')\n",
    "        for i in range(len(predict_class)):\n",
    "            f.write('%d,%s\\n'% (i+1,predict_class[i])) # i 从0开始\n",
    "            \n",
    "# output_file = \"../output/kaggle/working/cifar10-object-recognition-in-images-zip-file/submission.csv\"\n",
    "output_file = \"./cifar10/submission.csv\"\n",
    "generate_submissions(output_file,test_predict_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
