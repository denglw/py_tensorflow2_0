{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.2\n",
      "numpy 1.19.0\n",
      "pandas 1.0.5\n",
      "sklearn 0.23.1\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for model in mpl, np, pd, sklearn, keras:\n",
    "    print(model.__name__, model.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "# pandas读取csv\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pop()\n",
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n",
      "627\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)\n",
    "print(train_df.shape[0])\n",
    "print(eval_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x6db4f88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x6ef9d48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind = 'barh') # barv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d768088>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind = 'barh') #train_df.class函数关键字冲突"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7d8a88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([train_df,y_train], axis = 1).groupby('sex').survived.mean().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# feature_column\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class','deck', 'embark_town', 'alone'] # 离散列\n",
    "numeric_columns = ['age', 'fare'] # 连续列\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column,vocab)\n",
    "    # indicator_column 独热编码\n",
    "    # categorical_column_with_vocabulary_list 离散\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(categorical_column, vocab)))\n",
    "    \n",
    "# numeric_column 数值    \n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(numeric_column,dtype=tf.float64))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size =32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=11685, shape=(5,), dtype=string, numpy=array([b'male', b'female', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: id=11677, shape=(5,), dtype=float64, numpy=array([65., 42., 45., 66., 28.])>, 'n_siblings_spouses': <tf.Tensor: id=11683, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0])>, 'parch': <tf.Tensor: id=11684, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0])>, 'fare': <tf.Tensor: id=11682, shape=(5,), dtype=float64, numpy=array([ 26.55  , 227.525 ,   8.05  ,  10.5   ,  13.8625])>, 'class': <tf.Tensor: id=11679, shape=(5,), dtype=string, numpy=array([b'First', b'First', b'Third', b'Second', b'Second'], dtype=object)>, 'deck': <tf.Tensor: id=11680, shape=(5,), dtype=string, numpy=array([b'E', b'unknown', b'unknown', b'unknown', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: id=11681, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Cherbourg', b'Southampton', b'Southampton',\n",
      "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: id=11678, shape=(5,), dtype=string, numpy=array([b'y', b'y', b'y', b'y', b'y'], dtype=object)>} tf.Tensor([0 1 1 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(train_df,y_train,batch_size = 5)\n",
    "for x,y in train_dataset.take(1):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[19.]\n",
      " [14.]\n",
      " [28.]\n",
      " [23.]\n",
      " [30.]]\n",
      "WARNING:tensorflow:Layer dense_features_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeatures\n",
    "for x, y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[ 3.      1.      0.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      1.      0.      0.\n",
      "  41.5792  1.      0.      0.      0.      0.      0.      0.      0.\n",
      "   0.      1.      0.      0.      0.      0.      1.    ]\n",
      " [24.      1.      0.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  65.      1.      0.      0.      0.      0.      0.      0.      0.\n",
      "   0.      1.      0.      0.      0.      0.      1.    ]\n",
      " [44.      1.      0.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  26.      1.      0.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [36.      0.      1.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  10.5     0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [18.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.7958  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeatures\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01), \n",
    "              metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 19 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 7s 390ms/step - loss: 0.5073 - accuracy: 0.7632 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 1s 42ms/step - loss: 0.5198 - accuracy: 0.7516 - val_loss: 0.5027 - val_accuracy: 0.7461\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.76 - 0s 19ms/step - loss: 0.4983 - accuracy: 0.7632 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.5014 - accuracy: 0.7615 - val_loss: 0.4834 - val_accuracy: 0.7539\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.5295 - accuracy: 0.7368 - val_loss: 0.5126 - val_accuracy: 0.7383\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.7516 - val_loss: 0.4983 - val_accuracy: 0.7383\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.7681 - val_loss: 0.5147 - val_accuracy: 0.7812\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4883 - accuracy: 0.7763 - val_loss: 0.4902 - val_accuracy: 0.7422\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7533 - val_loss: 0.5375 - val_accuracy: 0.7578\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5043 - accuracy: 0.7730 - val_loss: 0.5055 - val_accuracy: 0.7617\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7714 - val_loss: 0.4970 - val_accuracy: 0.7578\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.7747 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5336 - accuracy: 0.7599 - val_loss: 0.7318 - val_accuracy: 0.6445\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5163 - accuracy: 0.7484 - val_loss: 0.4900 - val_accuracy: 0.7383\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7697 - val_loss: 0.5491 - val_accuracy: 0.7305\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7747 - val_loss: 0.4840 - val_accuracy: 0.7383\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4818 - accuracy: 0.7812 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.7549 - val_loss: 0.5183 - val_accuracy: 0.7422\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7549 - val_loss: 0.4898 - val_accuracy: 0.7305\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7615 - val_loss: 0.4899 - val_accuracy: 0.7461\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7796 - val_loss: 0.5058 - val_accuracy: 0.7305\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.79 - 0s 7ms/step - loss: 0.4752 - accuracy: 0.8076 - val_loss: 0.4778 - val_accuracy: 0.7383\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7796 - val_loss: 0.4850 - val_accuracy: 0.7461\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.7730 - val_loss: 0.4845 - val_accuracy: 0.7344\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7780 - val_loss: 0.4844 - val_accuracy: 0.7383\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7533 - val_loss: 0.5507 - val_accuracy: 0.7266\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.5163 - accuracy: 0.7467 - val_loss: 0.4965 - val_accuracy: 0.7734\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7648 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4982 - accuracy: 0.7763 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7681 - val_loss: 0.4806 - val_accuracy: 0.7422\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7911 - val_loss: 0.5029 - val_accuracy: 0.7422\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.7582 - val_loss: 0.5117 - val_accuracy: 0.7383\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7730 - val_loss: 0.4891 - val_accuracy: 0.7383\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7780 - val_loss: 0.4805 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7878 - val_loss: 0.4933 - val_accuracy: 0.7539\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7845 - val_loss: 0.4791 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7928 - val_loss: 0.6057 - val_accuracy: 0.7109\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5148 - accuracy: 0.7549 - val_loss: 0.5887 - val_accuracy: 0.7188\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4831 - accuracy: 0.7829 - val_loss: 0.4774 - val_accuracy: 0.7656\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5026 - accuracy: 0.7780 - val_loss: 0.5393 - val_accuracy: 0.7266\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5056 - accuracy: 0.7648 - val_loss: 0.5579 - val_accuracy: 0.7305\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7829 - val_loss: 0.6253 - val_accuracy: 0.7031\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7796 - val_loss: 0.4833 - val_accuracy: 0.7461\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7862 - val_loss: 0.5305 - val_accuracy: 0.7422\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5010 - accuracy: 0.7796 - val_loss: 0.4947 - val_accuracy: 0.7617\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7829 - val_loss: 0.4832 - val_accuracy: 0.7539\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4966 - accuracy: 0.7730 - val_loss: 0.5280 - val_accuracy: 0.7461\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.7812 - val_loss: 0.5319 - val_accuracy: 0.7422\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4876 - accuracy: 0.7977 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.7911 - val_loss: 0.4934 - val_accuracy: 0.7422\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7697 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.4703 - accuracy: 0.7796 - val_loss: 0.4742 - val_accuracy: 0.7656\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 0.5116 - accuracy: 0.7747 - val_loss: 0.5032 - val_accuracy: 0.7344\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7829 - val_loss: 0.4766 - val_accuracy: 0.7617\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4928 - accuracy: 0.7796 - val_loss: 0.4822 - val_accuracy: 0.7695\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.5214 - accuracy: 0.7484 - val_loss: 0.5072 - val_accuracy: 0.7461\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5042 - accuracy: 0.7599 - val_loss: 0.5175 - val_accuracy: 0.7695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.8059 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7845 - val_loss: 0.5182 - val_accuracy: 0.7539\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7911 - val_loss: 0.5810 - val_accuracy: 0.6602\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7796 - val_loss: 0.4836 - val_accuracy: 0.7461\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7977 - val_loss: 0.4835 - val_accuracy: 0.7539\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7944 - val_loss: 0.4823 - val_accuracy: 0.7578\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7697 - val_loss: 0.5852 - val_accuracy: 0.7148\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.7829 - val_loss: 0.5020 - val_accuracy: 0.7539\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7664 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7730 - val_loss: 0.4797 - val_accuracy: 0.7695\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7763 - val_loss: 0.4799 - val_accuracy: 0.7422\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7796 - val_loss: 0.4855 - val_accuracy: 0.7539\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7862 - val_loss: 0.5240 - val_accuracy: 0.7539\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7763 - val_loss: 0.4918 - val_accuracy: 0.7578\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7829 - val_loss: 0.5675 - val_accuracy: 0.7227\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7796 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7977 - val_loss: 0.4718 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7697 - val_loss: 0.5267 - val_accuracy: 0.7461\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7730 - val_loss: 0.4870 - val_accuracy: 0.7695\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7928 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7714 - val_loss: 0.4807 - val_accuracy: 0.7461\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7928 - val_loss: 0.5572 - val_accuracy: 0.7305\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.4535 - accuracy: 0.8125 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.5173 - accuracy: 0.7451 - val_loss: 0.4734 - val_accuracy: 0.7734\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7961 - val_loss: 0.4747 - val_accuracy: 0.7695\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7878 - val_loss: 0.4809 - val_accuracy: 0.7578\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7747 - val_loss: 0.4734 - val_accuracy: 0.7539\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.7845 - val_loss: 0.5638 - val_accuracy: 0.7070\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7862 - val_loss: 0.5492 - val_accuracy: 0.7266\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.8059 - val_loss: 0.5906 - val_accuracy: 0.7344\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7697 - val_loss: 0.6409 - val_accuracy: 0.6445\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7664 - val_loss: 0.5006 - val_accuracy: 0.7461\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7747 - val_loss: 0.4820 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7993 - val_loss: 0.4932 - val_accuracy: 0.7539\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.7763 - val_loss: 0.4795 - val_accuracy: 0.7734\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7977 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4817 - accuracy: 0.7878 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.5161 - accuracy: 0.7648 - val_loss: 0.4858 - val_accuracy: 0.7656\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.8010 - val_loss: 0.4751 - val_accuracy: 0.7578\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7664 - val_loss: 0.4943 - val_accuracy: 0.7539\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8109 - val_loss: 0.5366 - val_accuracy: 0.7344\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7961 - val_loss: 0.4903 - val_accuracy: 0.7578\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8043 - val_loss: 0.4820 - val_accuracy: 0.7578\n"
     ]
    }
   ],
   "source": [
    "# 1. model.fit\n",
    "# 2. model -> estimator -> train\n",
    "\n",
    "train_dataset = make_dataset(train_df,y_train,epochs = 100)\n",
    "eval_dataset = make_dataset(eval_df,y_eval,epochs=1,shuffle = False)\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data = eval_dataset,\n",
    "                    steps_per_epoch = 627//32,  # total/batch_size\n",
    "                    validation_steps = 264//32, \n",
    "                    epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp1y13c35x\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmp1y13c35x', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000000027AE5148>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-744076bf1de9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 2. return a. (features, labels)  b. dataset -> (feature,label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1190\u001b[1;33m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[1;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[1;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m       \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_model\u001b[1;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[1;32m--> 419\u001b[1;33m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[0;32m    420\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[1;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[0;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[1;32m--> 987\u001b[1;33m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[0;32m    988\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "# keras.estimator.model_to_estimator\n",
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "#estimator = tf.compat.v1.keras.estimator.model_to_estimator(model)\n",
    "# 1. function\n",
    "# 2. return  a. (features, labels)   b. dataset -> (feature,label)\n",
    "\n",
    "estimator.train(input_fn = lambda : make_dataset(train_df,y_train,epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
