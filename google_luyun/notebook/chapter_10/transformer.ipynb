{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.2\n",
      "numpy 1.19.0\n",
      "pandas 1.0.5\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "import time\n",
    "import sklearn \n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for model in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(model.__name__, model.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. loads data\n",
    "# 2. preprocesses data -> dataset\n",
    "# 3. tools\n",
    "# 3.1 generates position embedding\n",
    "# 3.2 create mask. (a. padding, b. decoder)\n",
    "# 3.3 scaled_dot_product_attention\n",
    "# 4. builds model\n",
    "# 4.1 MultiheadAttention\n",
    "# 4.2 EncoderLayer\n",
    "# 4.3 DecoderLayer\n",
    "# 4.4 EncoderModel\n",
    "# 4.5 DecoderModel\n",
    "# 4.6 Transformer\n",
    "# 5. optimizer & loss\n",
    "# 6. train step -> train\n",
    "# 7. Evaluate and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='ted_hrlr_translate',\n",
      "    version=1.0.0,\n",
      "    description='Data sets derived from TED talk transcripts for comparing similar language pairs\n",
      "where one is high resource and the other is low resource.',\n",
      "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
      "    features=Translation({\n",
      "        'en': Text(shape=(), dtype=tf.string),\n",
      "        'pt': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    total_num_examples=54781,\n",
      "    splits={\n",
      "        'test': 1803,\n",
      "        'train': 51785,\n",
      "        'validation': 1193,\n",
      "    },\n",
      "    supervised_keys=('pt', 'en'),\n",
      "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
      "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
      "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
      "      booktitle = {HLT-NAACL},\n",
      "      year    = {2018},\n",
      "      }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 手动下载地址 https://github.com/neulab/word-embeddings-for-nmt \n",
    "# qi18naacl-dataset.tar.gz\n",
    "examples, info = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                           with_info = True,\n",
    "                           as_supervised = True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'e quando melhoramos a procura , tiramos a \\xc3\\xbanica vantagem da impress\\xc3\\xa3o , que \\xc3\\xa9 a serendipidade .'\n",
      "b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .'\n",
      "\n",
      "b'mas e se estes fatores fossem ativos ?'\n",
      "b'but what if it were active ?'\n",
      "\n",
      "b'mas eles n\\xc3\\xa3o tinham a curiosidade de me testar .'\n",
      "b\"but they did n't test for curiosity .\"\n",
      "\n",
      "b'e esta rebeldia consciente \\xc3\\xa9 a raz\\xc3\\xa3o pela qual eu , como agn\\xc3\\xb3stica , posso ainda ter f\\xc3\\xa9 .'\n",
      "b'and this conscious defiance is why i , as an agnostic , can still have faith .'\n",
      "\n",
      "b\"`` `` '' podem usar tudo sobre a mesa no meu corpo . ''\"\n",
      "b'you can use everything on the table on me .'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pt, en in train_examples.take(5):\n",
    "    print(pt.numpy())\n",
    "    print(en.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples),\n",
    "    target_vocab_size = 2 ** 13)\n",
    "pt_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples),\n",
    "    target_vocab_size = 2 ** 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string is Transformer is awesome.\n",
      "7915 --> \"T\"\n",
      "1248 --> \"ran\"\n",
      "7946 --> \"s\"\n",
      "7194 --> \"former \"\n",
      "13 --> \"is \"\n",
      "2799 --> \"awesome\"\n",
      "7877 --> \".\"\n"
     ]
    }
   ],
   "source": [
    "sample_string = \"Transformer is awesome.\"\n",
    "\n",
    "tokenized_string = en_tokenizer.encode(sample_string)\n",
    "print('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "origin_string = en_tokenizer.decode(tokenized_string)\n",
    "print('The original string is {}'.format(origin_string))\n",
    "\n",
    "assert origin_string == sample_string\n",
    "\n",
    "for token in tokenized_string:\n",
    "    print('{} --> \"{}\"'.format(token, en_tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "def encode_to_subword(pt_sentence, en_sentence):\n",
    "    pt_sequence = [pt_tokenizer.vocab_size] \\\n",
    "    + pt_tokenizer.encode(pt_sentence.numpy()) \\\n",
    "    + [pt_tokenizer.vocab_size + 1]\n",
    "    en_sequence = [en_tokenizer.vocab_size] \\\n",
    "    + en_tokenizer.encode(en_sentence.numpy()) \\\n",
    "    + [en_tokenizer.vocab_size + 1]\n",
    "    return pt_sequence, en_sequence\n",
    "\n",
    "def filter_by_max_length(pt, en):\n",
    "    return tf.logical_and(tf.size(pt) <= max_length,\n",
    "                          tf.size(en) <= max_length)\n",
    "\n",
    "def tf_encode_to_subword(pt_sentence, en_sentence):\n",
    "    return tf.py_function(encode_to_subword,\n",
    "                          [pt_sentence, en_sentence],\n",
    "                          [tf.int64, tf.int64])\n",
    "train_dataset = train_examples.map(tf_encode_to_subword)\n",
    "train_dataset = train_dataset.filter(filter_by_max_length)\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    buffer_size).padded_batch(\n",
    "    batch_size, padded_shapes=([-1], [-1]))\n",
    "\n",
    "valid_dataset = val_examples.map(tf_encode_to_subword)\n",
    "valid_dataset = valid_dataset.filter(\n",
    "    filter_by_max_length).padded_batch(\n",
    "    batch_size, padded_shapes=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "# PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))\n",
    "# PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "\n",
    "# pos.shape: [sentence_length, 1]\n",
    "# i.shape  : [1, d_model]\n",
    "# result.shape: [sentence_length, d_model]\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000,\n",
    "                               (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def get_position_embedding(sentence_length, d_model):\n",
    "    angle_rads = get_angles(np.arange(sentence_length)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "    # sines.shape: [sentence_length, d_model / 2]\n",
    "    # cosines.shape: [sentence_length, d_model / 2]\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    # position_embedding.shape: [sentence_length, d_model]\n",
    "    position_embedding = np.concatenate([sines, cosines], axis = -1)\n",
    "    # position_embedding.shape: [1, sentence_length, d_model]\n",
    "    position_embedding = position_embedding[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(position_embedding, dtype=tf.float32)\n",
    "\n",
    "position_embedding = get_position_embedding(50, 512)\n",
    "print(position_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_position_embedding(position_embedding):\n",
    "    plt.pcolormesh(position_embedding[0], cmap = 'RdBu')\n",
    "    plt.xlabel('Depth')\n",
    "    plt.xlim((0, 512))\n",
    "    plt.ylabel('Position')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "plot_position_embedding(position_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207437, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. padding mask, 2. look ahead\n",
    "\n",
    "# batch_data.shape: [batch_size, seq_len]\n",
    "def create_padding_mask(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)\n",
    "    # [batch_size, 1, 1, seq_len]\n",
    "    return padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207445, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention_weights.shape: [3,3]\n",
    "# [[1, 0, 0],\n",
    "#  [4, 5, 0],\n",
    "#  [7, 8, 9]]\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask # (seq_len, seq_len)\n",
    "\n",
    "create_look_ahead_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - q: shape == (..., seq_len_q, depth)\n",
    "    - k: shape == (..., seq_len_k, depth)\n",
    "    - v: shape == (..., seq_len_v, depth_v)\n",
    "    - seq_len_k == seq_len_v\n",
    "    - mask: shape == (..., seq_len_q, seq_len_k)\n",
    "    Returns:\n",
    "    - output: weighted sum\n",
    "    - attention_weights: weights of attention\n",
    "    \"\"\"\n",
    "    \n",
    "    # matmul_qk.shape: (..., seq_len_q, seq_len_k)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b = True)\n",
    "    \n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # 使得在softmax后值趋近于0\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    # attention_weights.shape: (..., seq_len_q, seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(\n",
    "        scaled_attention_logits, axis = -1)\n",
    "    \n",
    "    # output.shape: (..., seq_len_q, depth_v)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "def print_scaled_dot_product_attention(q, k, v):\n",
    "    temp_out, temp_att = scaled_dot_product_attention(q, k, v, None)\n",
    "    print(\"Attention weights are:\")\n",
    "    print(temp_att)\n",
    "    print(\"Output is:\")\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_k = tf.constant([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=tf.float32) # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=tf.float32) # (4, 2)\n",
    "\n",
    "temp_q1 = tf.constant([[0, 10, 0]], dtype=tf.float32) # (1, 3)\n",
    "np.set_printoptions(suppress=True)\n",
    "print_scaled_dot_product_attention(temp_q1, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q2 = tf.constant([[0, 0, 10]], dtype=tf.float32) # (1, 3)\n",
    "print_scaled_dot_product_attention(temp_q2, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q3 = tf.constant([[10, 10, 0]], dtype=tf.float32) # (1, 3)\n",
    "print_scaled_dot_product_attention(temp_q3, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  1.  0.  0. ]\n",
      " [0.  0.  0.5 0.5]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[ 10.    0. ]\n",
      " [550.    5.5]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q4 = tf.constant([[0, 10, 0],\n",
    "                       [0, 0, 10],\n",
    "                       [10, 10, 0]], dtype=tf.float32) # (3, 3)\n",
    "print_scaled_dot_product_attention(temp_q4, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512)\n",
      "(1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    理论上:\n",
    "    x -> Wq0 -> q0\n",
    "    x -> Wk0 -> k0\n",
    "    x -> Wv0 -> v0\n",
    "    \n",
    "    实战中:\n",
    "    q -> Wq0 -> q0\n",
    "    k -> Wk0 -> k0\n",
    "    v -> Wv0 -> v0\n",
    "    \n",
    "    实战中技巧：\n",
    "    q -> Wq -> Q -> split -> q0, q1, q2...\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        \n",
    "        self.WQ = keras.layers.Dense(self.d_model)\n",
    "        self.WK = keras.layers.Dense(self.d_model)\n",
    "        self.WV = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "        self.dense = keras.layers.Dense(self.d_model)\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        # x.shape: (batch_size, seq_len, d_model)\n",
    "        # d_model = num_heads * depth\n",
    "        # x -> (batch_size, num_heads, seq_len, depth)\n",
    "        \n",
    "        x = tf.reshape(x,\n",
    "                       (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.WQ(q) # q.shape: (batch_size, seq_len_q, d_model)\n",
    "        k = self.WK(k) # k.shape: (batch_size, seq_len_k, d_model)\n",
    "        v = self.WV(v) # v.shape: (batch_size, seq_len_v, d_model)\n",
    "        \n",
    "        # q.shape: (batch_size, num_heads, seq_len_q, depth)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        # k.shape: (batch_size, num_heads, seq_len_k, depth)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        # v.shape: (batch_size, num_heads, seq_len_v, depth)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # scaled_attention_outputs.shape: (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape: (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention_outputs, attention_weights = \\\n",
    "        scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        # scaled_attention_outputs.shape: (batch_size, seq_len_q, num_heads, depth)\n",
    "        scaled_attention_outputs = tf.transpose(\n",
    "            scaled_attention_outputs, perm = [0, 2, 1, 3])\n",
    "        # concat_attention.shape: (batch_size, seq_len_q, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention_outputs,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # output.shape : (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output, attention_weights\n",
    "    \n",
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 256)) # (batch_size, seq_len_q, dim)\n",
    "output, attn = temp_mha(y, y, y, mask = None)\n",
    "print(output.shape)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feed_forward_network(d_model, dff):\n",
    "    # dff: dim of feed forward network.\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(dff, activation='relu'),\n",
    "        keras.layers.Dense(d_model)\n",
    "    ])\n",
    "\n",
    "sample_ffn = feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    x -> self attention -> add & normalize & dropout\n",
    "      -> feed_forward -> add & normalize & dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(\n",
    "            epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(\n",
    "            epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, encoder_padding_mask):\n",
    "        # x.shape          : (batch_size, seq_len, dim=d_model)\n",
    "        # attn_output.shape: (batch_size, seq_len, d_model)\n",
    "        # out1.shape       : (batch_size, seq_len, d_model)\n",
    "        attn_output, _ = self.mha(x, x, x, encoder_padding_mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layer_norm1(x + attn_output)\n",
    "        \n",
    "        # ffn_output.shape: (batch_size, seq_len, d_model)\n",
    "        # out2.shape      : (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layer_norm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "\n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sample_input = tf.random.uniform((64, 50, 512))\n",
    "sample_output = sample_encoder_layer(sample_input, False, None)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512)\n",
      "(64, 8, 60, 60)\n",
      "(64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    x -> self attention -> add & normalize & dropout -> out1\n",
    "    out1 , encoding_outputs -> attention -> add & normalize & dropout -> out2\n",
    "    out2 -> ffn -> add & normalize & dropout -> out3\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(\n",
    "            epsilon = 1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(\n",
    "            epsilon = 1e-6)\n",
    "        self.layer_norm3 = keras.layers.LayerNormalization(\n",
    "            epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, encoding_outputs, training,\n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # decoder_mask: 由look_ahead_mask和decoder_padding_mask合并而来\n",
    "        \n",
    "        # x.shape: (batch_size, target_seq_len, d_model)\n",
    "        # encoding_outputs.shape: (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # attn1, out1.shape : (batch_size, target_seq_len, d_model)\n",
    "        attn1, attn_weights1 = self.mha1(x, x, x, decoder_mask)\n",
    "        attn1 = self.dropout1(attn1, training = training)\n",
    "        out1 = self.layer_norm1(attn1 + x)\n",
    "        \n",
    "        # attn2, out2.shape : (batch_size, target_seq_len, d_model)\n",
    "        attn2, attn_weights2 = self.mha2(\n",
    "            out1, encoding_outputs, encoding_outputs,\n",
    "            encoder_decoder_padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training = training)\n",
    "        out2 = self.layer_norm2(attn2 + out1)\n",
    "        \n",
    "        # ffn_output, out3.shape: (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layer_norm3(ffn_output + out2)\n",
    "        \n",
    "        return out3, attn_weights1, attn_weights2\n",
    "    \n",
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "sample_decoder_input = tf.random.uniform((64, 60, 512))\n",
    "sample_decoder_output, sample_decoder_attn_weights1, sample_decoder_attn_weights2 = sample_decoder_layer(\n",
    "    sample_decoder_input, sample_output, False, None, None)\n",
    "\n",
    "print(sample_decoder_output.shape)\n",
    "print(sample_decoder_attn_weights1.shape)\n",
    "print(sample_decoder_attn_weights2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, input_vocab_size, max_length,\n",
    "                 d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size,\n",
    "                                                self.d_model)\n",
    "        # position_embedding.shape: (1, max_length, d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length,\n",
    "                                                         self.d_model)\n",
    "        \n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.encoder_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff, rate)\n",
    "            for _ in range(self.num_layers)]\n",
    "        \n",
    "    \n",
    "    def call(self, x, training, encoder_padding_mask):\n",
    "        # x.shape: (batch_size, input_seq_len)\n",
    "        input_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(\n",
    "            input_seq_len, self.max_length,\n",
    "            \"input_seq_len should be less or equal to self.max_length\")\n",
    "        \n",
    "        # x.shape: (batch_size, input_seq_len, d_model)\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.position_embedding[:, :input_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, training,\n",
    "                                       encoder_padding_mask)\n",
    "        \n",
    "        # x.shape: (batch_size, input_seq_len, d_model)\n",
    "        return x\n",
    "    \n",
    "sample_encoder_model = EncoderModel(2, 8500, max_length,\n",
    "                                    512, 8, 2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64, 37))\n",
    "sample_encoder_model_output = sample_encoder_model(\n",
    "    sample_encoder_model_input, False, encoder_padding_mask = None)\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 512)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, target_vocab_size, max_length,\n",
    "                 d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size,\n",
    "                                                d_model)\n",
    "        self.position_embedding = get_position_embedding(max_length,\n",
    "                                                         d_model)\n",
    "        \n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.decoder_layers = [\n",
    "            DecoderLayer(d_model, num_heads, dff, rate)\n",
    "            for _ in range(self.num_layers)]\n",
    "        \n",
    "    \n",
    "    def call(self, x, encoding_outputs, training,\n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # x.shape: (batch_size, output_seq_len)\n",
    "        output_seq_len = tf.shape(x)[1]\n",
    "        tf.debugging.assert_less_equal(\n",
    "            output_seq_len, self.max_length,\n",
    "            \"output_seq_len should be less or equal to self.max_length\")\n",
    "        \n",
    "        attention_weights = {}\n",
    "        \n",
    "        # x.shape: (batch_size, output_seq_len, d_model)\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.position_embedding[:, :output_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, attn1, attn2 = self.decoder_layers[i](\n",
    "                x, encoding_outputs, training,\n",
    "                decoder_mask, encoder_decoder_padding_mask)\n",
    "            attention_weights[\n",
    "                'decoder_layer{}_att1'.format(i+1)] = attn1\n",
    "            attention_weights[\n",
    "                'decoder_layer{}_att2'.format(i+1)] = attn2\n",
    "        # x.shape: (batch_size, output_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "\n",
    "sample_decoder_model = DecoderModel(2, 8000, max_length,\n",
    "                                    512, 8, 2048)\n",
    "\n",
    "sample_decoder_model_input = tf.random.uniform((64, 35))\n",
    "sample_decoder_model_output, sample_decoder_model_att \\\n",
    "= sample_decoder_model(\n",
    "    sample_decoder_model_input,\n",
    "    sample_encoder_model_output,\n",
    "    training = False, decoder_mask = None,\n",
    "    encoder_decoder_padding_mask = None)\n",
    "\n",
    "print(sample_decoder_model_output.shape)\n",
    "for key in sample_decoder_model_att:\n",
    "    print(sample_decoder_model_att[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 8000)\n",
      "decoder_layer1_att1 (64, 8, 31, 31)\n",
      "decoder_layer1_att2 (64, 8, 31, 26)\n",
      "decoder_layer2_att1 (64, 8, 31, 31)\n",
      "decoder_layer2_att2 (64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, input_vocab_size, target_vocab_size,\n",
    "                 max_length, d_model, num_heads, dff, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder_model = EncoderModel(\n",
    "            num_layers, input_vocab_size, max_length,\n",
    "            d_model, num_heads, dff, rate)\n",
    "        \n",
    "        self.decoder_model = DecoderModel(\n",
    "            num_layers, target_vocab_size, max_length,\n",
    "            d_model, num_heads, dff, rate)\n",
    "        \n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, encoder_padding_mask,\n",
    "             decoder_mask, encoder_decoder_padding_mask):\n",
    "        # encoding_outputs.shape: (batch_size, input_seq_len, d_model)\n",
    "        encoding_outputs = self.encoder_model(\n",
    "            inp, training, encoder_padding_mask)\n",
    "        \n",
    "        # decoding_outputs.shape: (batch_size, output_seq_len, d_model)\n",
    "        decoding_outputs, attention_weights = self.decoder_model(\n",
    "            tar, encoding_outputs, training,\n",
    "            decoder_mask, encoder_decoder_padding_mask)\n",
    "        \n",
    "        # predictions.shape: (batch_size, output_seq_len, target_vocab_size)\n",
    "        predictions = self.final_layer(decoding_outputs)\n",
    "        \n",
    "        return predictions, attention_weights\n",
    "    \n",
    "sample_transformer = Transformer(2, 8500, 8000, max_length,\n",
    "                                 512, 8, 2048, rate = 0.1)\n",
    "temp_input = tf.random.uniform((64, 26))\n",
    "temp_target = tf.random.uniform((64, 31))\n",
    "\n",
    "predictions, attention_weights = sample_transformer(\n",
    "    temp_input, temp_target, training = False,\n",
    "    encoder_padding_mask = None,\n",
    "    decoder_mask = None,\n",
    "    encoder_decoder_padding_mask = None)\n",
    "\n",
    "print(predictions.shape)\n",
    "for key in attention_weights:\n",
    "    print(key, attention_weights[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. initializes model.\n",
    "# 2. define loss, optimizer, learning_rate schedule\n",
    "# 3. train_step\n",
    "# 4. train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = pt_tokenizer.vocab_size + 2\n",
    "target_vocab_size = en_tokenizer.vocab_size + 2\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(num_layers,\n",
    "                          input_vocab_size,\n",
    "                          target_vocab_size,\n",
    "                          max_length,\n",
    "                          d_model, num_heads, dff, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrate = (d_model ** -0.5) * min(step_num ** (-0.5),\n",
    "#                                 step_num * warm_up_steps **(-1.5))\n",
    "\n",
    "class CustomizedSchedule(\n",
    "    keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps = 4000):\n",
    "        super(CustomizedSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** (-1.5))\n",
    "        \n",
    "        arg3 = tf.math.rsqrt(self.d_model)\n",
    "        \n",
    "        return arg3 * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = CustomizedSchedule(d_model)\n",
    "optimizer = keras.optimizers.Adam(learning_rate,\n",
    "                                  beta_1 = 0.9,\n",
    "                                  beta_2 = 0.98,\n",
    "                                  epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train step')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomizedSchedule(d_model)\n",
    "\n",
    "plt.plot(\n",
    "    temp_learning_rate_schedule(\n",
    "        tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Leraning rate\")\n",
    "plt.xlabel(\"Train step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits = True, reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    \"\"\"\n",
    "    Encoder:\n",
    "      - encoder_padding_mask (self attention of EncoderLayer)\n",
    "    Decoder:\n",
    "      - look_ahead_mask (self attention of DecoderLayer)\n",
    "      - encoder_decoder_padding_mask (encoder-decoder attention of DecoderLayer)\n",
    "      - decoder_padding_mask (self attention of DecoderLayer)\n",
    "    \"\"\"\n",
    "    encoder_padding_mask = create_padding_mask(inp)\n",
    "    encoder_decoder_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    decoder_padding_mask = create_padding_mask(tar)\n",
    "    decoder_mask = tf.maximum(decoder_padding_mask,\n",
    "                              look_ahead_mask)\n",
    "    \n",
    "    return encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_inp, temp_tar = iter(train_dataset.take(1)).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37)\n",
      "(64, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=305066, shape=(64, 1, 1, 37), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=305098, shape=(64, 1, 38, 38), dtype=float32, numpy=\n",
       " array([[[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 1., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 1., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.],\n",
       "          [0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=305073, shape=(64, 1, 1, 37), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp_inp.shape)\n",
    "print(temp_tar.shape)\n",
    "create_masks(temp_inp, temp_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.2143 Accuracy 0.0000\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 10 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 10 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 13 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 13 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function train_step at 0x00000000227931F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 100 Loss 4.1841 Accuracy 0.0155\n"
     ]
    }
   ],
   "source": [
    "train_loss = keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = keras.metrics.SparseCategoricalAccuracy(\n",
    "    name = 'train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp  = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask \\\n",
    "    = create_masks(inp, tar_inp)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, True,\n",
    "                                     encoder_padding_mask,\n",
    "                                     decoder_mask,\n",
    "                                     encoder_decoder_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(gradients, transformer.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                epoch + 1, batch, train_loss.result(),\n",
    "                train_accuracy.result()))\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "        epoch + 1, train_loss.result(), train_accuracy.result()))\n",
    "    print('Time take for 1 epoch: {} secs\\n'.format(\n",
    "        time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "eg: A B C D -> E F G H.\n",
    "Train: A B C D, E F G -> F G H\n",
    "Eval:  A B C D -> E\n",
    "       A B C D, E -> F\n",
    "       A B C D, E F -> G\n",
    "       A B C D, E F G -> H\n",
    "\"\"\"\n",
    "def evaluate(inp_sentence):\n",
    "    input_id_sentence = [pt_tokenizer.vocab_size] \\\n",
    "    + pt_tokenizer.encode(inp_sentence) + [pt_tokenizer.vocab_size + 1]\n",
    "    # encoder_input.shape: (1, input_sentence_length)\n",
    "    encoder_input = tf.expand_dims(input_id_sentence, 0)\n",
    "    \n",
    "    # decoder_input.shape: (1, 1)\n",
    "    decoder_input = tf.expand_dims([en_tokenizer.vocab_size], 0)\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask \\\n",
    "        = create_masks(encoder_input, decoder_input)\n",
    "        # predictions.shape: (batch_size, output_target_len, target_vocab_size)\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input,\n",
    "            decoder_input,\n",
    "            False,\n",
    "            encoder_padding_mask,\n",
    "            decoder_mask,\n",
    "            encoder_decoder_padding_mask)\n",
    "        # predictions.shape: (batch_size, target_vocab_size)\n",
    "        predictions = predictions[:, -1, :]\n",
    "        \n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis = -1),\n",
    "                               tf.int32)\n",
    "        \n",
    "        if tf.equal(predicted_id, en_tokenizer.vocab_size + 1):\n",
    "            return tf.squeeze(decoder_input, axis = 0), attention_weights\n",
    "        \n",
    "        decoder_input = tf.concat([decoder_input, [predicted_id]],\n",
    "                                  axis = -1)\n",
    "    return tf.squeeze(decoder_input, axis = 0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encoder_decoder_attention(attention, input_sentence,\n",
    "                                   result, layer_name):\n",
    "    fig = plt.figure(figsize = (16, 8))\n",
    "    \n",
    "    input_id_sentence = pt_tokenizer.encode(input_sentence)\n",
    "    \n",
    "    # attention.shape: (num_heads, tar_len, input_len)\n",
    "    attention = tf.squeeze(attention[layer_name], axis = 0)\n",
    "    \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head + 1)\n",
    "        \n",
    "        ax.matshow(attention[head][:-1, :])\n",
    "        \n",
    "        fontdict = {'fontsize': 10}\n",
    "        \n",
    "        ax.set_xticks(range(len(input_id_sentence) + 2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "        \n",
    "        ax.set_ylim(len(result) - 1.5, -0.5)\n",
    "        \n",
    "        ax.set_xticklabels(\n",
    "            ['<start>'] + [pt_tokenizer.decode([i]) for i in input_id_sentence] + ['<end>'],\n",
    "            fontdict = fontdict, rotation = 90)\n",
    "        ax.set_yticklabels(\n",
    "            [en_tokenizer.decode([i]) for i in result if i < en_tokenizer.vocab_size],\n",
    "            fontdict = fontdict)\n",
    "        ax.set_xlabel('Head {}'.format(head + 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence, layer_name = ''):\n",
    "    result, attention_weights = evaluate(input_sentence)\n",
    "    \n",
    "    predicted_sentence = en_tokenizer.decode(\n",
    "        [i for i in result if i < en_tokenizer.vocab_size])\n",
    "    \n",
    "    print(\"Input: {}\".format(input_sentence))\n",
    "    print(\"Predicted translation: {}\".format(predicted_sentence))\n",
    "    \n",
    "    if layer_name:\n",
    "        plot_encoder_decoder_attention(attention_weights, input_sentence,\n",
    "                                       result, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('está muito frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('isto é minha vida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('você ainda está em casa?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('este é o primeiro livro que eu já li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('este é o primeiro livro que eu já li',\n",
    "          layer_name = 'decoder_layer4_att2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
